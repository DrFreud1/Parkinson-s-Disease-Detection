{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary modules and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'shape' from 'C:\\\\Users\\\\USER\\\\Documents\\\\Yachay_Tech\\\\Thesis_Project\\\\ParkinsonsDetection\\\\python_scripts\\\\shape.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PyQt5\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# %matplotlib inline\n",
    "%matplotlib qt5\n",
    "#python packages\n",
    "import numpy as np\n",
    "# import cupy as cp\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import pac\n",
    "import warnings\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "import imp\n",
    "import shape\n",
    "import utils\n",
    "from eegstats import eegstats\n",
    "from load_features import load_WaveformShape_features, Bandpower_features, mean_and_peak_freqs, statistics\n",
    "\n",
    "imp.reload(utils)\n",
    "imp.reload(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and meta-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data and meta-data\n",
    "\"\"\"Which 'comparison' to make:\n",
    "    1. Off-med vs Controls\n",
    "    2. On-med vs Controls\n",
    "    3. Off-med vs On-med\n",
    "    \"\"\"\n",
    "comparison = 1\n",
    "data_repository = 'UNM' #USDiego for dataset from University of San Diego, UNM for dataset from U New Mexico\n",
    "all_chan = False\n",
    "EO = False\n",
    "bands = [[0.5,4], [4,8], [8,12], [16,32], [32,64]] #Delta, Theta, Alpha, Beta, Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Fs, t, S, Sc, Smed, flo, fhi = utils.loadmeta() \n",
    "eeg,rejects = utils.loadPD(EO, all_chan, data_repository) # EO means Eyes Opened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,j,k in zip(range(0,len(eeg['off'])), range(0,len(eeg['on'])), range(0,len(eeg['C']))):\n",
    "#     eeg['off'][:][i] = (eeg['off'][:][i]-np.mean(eeg['off'][:][i]))/np.max(abs(eeg['off'][:][i]))\n",
    "#     eeg['on'][:][j] = (eeg['on'][:][j]-np.mean(eeg['on'][:][j]))/np.max(abs(eeg['on'][:][j]))\n",
    "#     eeg['C'][:][k] = (eeg['C'][:][k]-np.mean(eeg['C'][:][k]))/np.max(abs(eeg['C'][:][k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploting a signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a signal\n",
    "sns.set(font_scale=1.2)\n",
    "data = eeg['off'][1]\n",
    "time = np.arange(data.size) / Fs\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "plt.plot(time, data, lw=1.5, color='k')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Voltage')\n",
    "plt.xlim([time.min(), time.max()])\n",
    "plt.title('EEG Signal for PD patients off-medication')\n",
    "sns.despine()\n",
    "\n",
    "# plt.plot(eeg['off'][6,0:10],label='control')\n",
    "# plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features of class I\n",
    "cl_B    = np.ones((S,1)) # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features of class II\n",
    "if comparison == 1 or comparison == 3:\n",
    "    cl_C    = np.zeros((Smed,1)) # transition means 0 #Original line\n",
    "elif comparison == 2:\n",
    "    cl_C    = np.ones((Smed,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features of class III\n",
    "cl_E    = np.zeros((Sc,1)) # -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_off = np.zeros((28165,1526))\n",
    "# for i in range(len(eeg['off'])):\n",
    "#     X_off[:,i] = eeg['off'][i][:28165]\n",
    "    \n",
    "# X_C = np.zeros((28165,1509))\n",
    "# for i in range(len(eeg['C'])):\n",
    "#     X_C[:,i] = eeg['C'][i][:28165]\n",
    "\n",
    "# X = np.concatenate((X_off, X_C), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_signal = 2347 #28165 max\n",
    "\n",
    "X_off = np.zeros((S,len_signal))\n",
    "for i in range(len(eeg['off'])):\n",
    "    X_off[i,:] = eeg['off'][i][:len_signal]\n",
    "    \n",
    "X_C = np.zeros((Sc,len_signal))\n",
    "for i in range(len(eeg['C'])):\n",
    "    X_C[i,:] = eeg['C'][i][:len_signal]\n",
    "\n",
    "X = np.concatenate((X_off, X_C), axis=0)\n",
    "# X = normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate((np.ravel(cl_B), np.ravel(cl_E)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=425156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_test = to_categorical(y_test)\n",
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical \n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import timeit\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D, ZeroPadding1D\n",
    "from keras.optimizers import SGD\n",
    "#import cv2, numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(453, 2347, 1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_classes = 2\n",
    "epochs = 30\n",
    "input_shape=(X_train.shape[1], 1)\n",
    "# input_shape =(X_train.shape[0],X_train.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2347, 1)\n"
     ]
    }
   ],
   "source": [
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Convolution1D, ZeroPadding1D, MaxPooling1D, BatchNormalization, Activation, Dropout, Flatten, Dense\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM and CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 2347, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 1173, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1173, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 1173, 128)         98432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 586, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 586, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 100)               91600     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 191,258\n",
      "Trainable params: 191,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Conv1D(256, kernel_size=3,padding = 'same',activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.summary()\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.fit(X_train, y_train, epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2/2 [==============================] - 1s 313ms/step - loss: 0.6860 - accuracy: 0.5077\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.6751 - accuracy: 0.5077\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.6687 - accuracy: 0.5121\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 0.6634 - accuracy: 0.5121\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 0.6582 - accuracy: 0.5276\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 0.6494 - accuracy: 0.5497\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - 0s 221ms/step - loss: 0.6453 - accuracy: 0.5894\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 0s 224ms/step - loss: 0.6303 - accuracy: 0.6578\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.6174 - accuracy: 0.6711\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 0.6121 - accuracy: 0.6865\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.6364 - accuracy: 0.6600\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 0.6111 - accuracy: 0.6711\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.6117 - accuracy: 0.6689\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.6076 - accuracy: 0.6932\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.6088 - accuracy: 0.6865\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.6026 - accuracy: 0.6976\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - 0s 221ms/step - loss: 0.5983 - accuracy: 0.6909\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.5947 - accuracy: 0.6909\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - 0s 223ms/step - loss: 0.5892 - accuracy: 0.7042\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.5908 - accuracy: 0.6954\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 0.6060 - accuracy: 0.6843\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - 0s 221ms/step - loss: 0.5859 - accuracy: 0.6932\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 0.6115 - accuracy: 0.6689\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 0.5833 - accuracy: 0.7020\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.6020 - accuracy: 0.6777\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - 0s 224ms/step - loss: 0.5920 - accuracy: 0.6821\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - 0s 221ms/step - loss: 0.5898 - accuracy: 0.7042\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 0.5974 - accuracy: 0.6909\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - 0s 221ms/step - loss: 0.5828 - accuracy: 0.7042\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.5830 - accuracy: 0.6887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x217ddc68a00>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6223 - accuracy: 0.6923\n",
      "Test loss: 0.6223288178443909\n",
      "Test accuracy: 0.692307710647583\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_22 (Conv1D)           (None, 2347, 128)         512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2347, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 1173, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 1173, 128)         49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1173, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 586, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 75008)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                4800576   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 4,854,034\n",
      "Trainable params: 4,853,522\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# intput_shape=(x_train.shape[1], 1)\n",
    "model.add(Conv1D(128, kernel_size=3,padding = 'same',activation='relu', input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Conv1D(128,kernel_size=3,padding = 'same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "#model.add(Conv1D(64,kernel_size=3,padding = 'same', activation='relu'))\n",
    "#model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.7407 - accuracy: 0.5607\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.6174 - accuracy: 0.6976\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.6061 - accuracy: 0.7042\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.5892 - accuracy: 0.7241\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.5754 - accuracy: 0.7263\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.5326 - accuracy: 0.7594\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.5277 - accuracy: 0.7550\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.5180 - accuracy: 0.7748\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.5014 - accuracy: 0.7815\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.4975 - accuracy: 0.7881\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.4665 - accuracy: 0.8057\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.4621 - accuracy: 0.8124\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.4306 - accuracy: 0.8190\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.4248 - accuracy: 0.8190\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.4238 - accuracy: 0.8146\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.4065 - accuracy: 0.8587\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.3888 - accuracy: 0.8389\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.3928 - accuracy: 0.8675\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.3801 - accuracy: 0.8587\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.3704 - accuracy: 0.8631\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.3528 - accuracy: 0.8742\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.3355 - accuracy: 0.8830\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.3258 - accuracy: 0.8808\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.3188 - accuracy: 0.8874\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.3089 - accuracy: 0.8985\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.3079 - accuracy: 0.9161\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.3020 - accuracy: 0.9095\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.2759 - accuracy: 0.9095\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.2727 - accuracy: 0.9073\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.2785 - accuracy: 0.9227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x217d30f6400>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 10ms/step - loss: 1.2678 - accuracy: 0.5333\n",
      "Test loss: 1.2678425312042236\n",
      "Test accuracy: 0.5333333611488342\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
